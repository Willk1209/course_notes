# 002.Multi-task & Meta Learning Basics

## Plan for Today

#### Multi-Task Learning

- Problem statement 
- Models, objectives, optimization 
- Challenges 
- Case study of real-world multi-task learning

#### Transfer Learning

- Pre-training & fine-tuning

- Problem formulation

#### Meta-Learning

- Problem formulation

- <u>General recipe of meta-learning algorithms</u> 
- <u>Black-box adaptation approaches</u> (The underline above includes the topic of HW1)
- Case study of GPT-3 (time-permitting)

#### Goals for by the end of lecture:

- Know the **key design decisions** when building multi-task learning systems
- Understand the **difference** between **multi-task learning** and **transfer learning**
- Understand the **basics** of **transfer learning**

- **Differences** between <u>multi-task learning, transfer learning, and meta-learning</u>
- Problems Basics of **transfer learning via fine-tuning**
- **Training set-up** for **few-shot meta-learning** algorithms
- How to implement **black-box meta-learning** techniques



## Some notations

- For a single-task learning(supervised):
  $$
  \mathcal D=\{(x,y)_k\}\\
  \min\limits_{\theta}\mathcal L(\theta,\mathcal D)
  $$

- Typical loss: negative log likelihood
  $$
  \mathcal L(\theta,\mathcal D)=-E_{(x,y)\sim \mathcal D [logf_\theta(y|x)]}
  $$

- <u>**What is a task**</u>?

$$
\mathcal T\triangleq \{p_i(x),p_i(y|x),\mathcal L_i\}
$$

- **Task descriptor** (z_i) : e.g. one-hot encoding of the task index or, whatever meta-data you have
  - personalization: user features/attributes
  - language description of the task
  - formal specifications of the task

$$
f_\theta(y|x) - > f_\theta(y|x,z_i)
$$

Vanilla MTL Objective: 
$$
\min\limits_{\theta}\sum\limits_{i=1}^{T}\mathcal L(\theta,\mathcal D_i)
$$

- To optimize the objective:
  $$
  \min\limits_{\theta}\sum\limits_{i=1}^{T}\mathcal L(\theta,\mathcal D_i)
  $$
  Basic Version:

  1. Sample mini-batch of tasks B ∼ {𝒯*i*}
  2. Sample mini-batch datapoints for each task 𝒟*i* ∼ 𝒟*i*
  3. Compute loss on the mini-batch: L̂ (*θ*, B) = ∑ L*k*(*θ*, 𝒟*b**k*)
  4. Backpropagate loss to compute gradient ∇*θ*L̂
  5. Apply gradient with your favorite neural net optimizer (e.g. Adam)



### Challenge

1. Negative transfer
2. Overfitting  
3. ......





## Meta-Learning

